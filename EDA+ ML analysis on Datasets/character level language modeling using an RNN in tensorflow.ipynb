{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length:  1112350\n"
     ]
    }
   ],
   "source": [
    "with open('1268-0.txt','r') as fp:\n",
    "    text= fp.read()\n",
    "start_indx= text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx= text.find('End of the Project Gutenberg')\n",
    "text= text[start_indx : end_indx]\n",
    "char_set= set(text)\n",
    "print('Total Length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Characters:  80\n"
     ]
    }
   ],
   "source": [
    "print('Unique Characters: ', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted= sorted(char_set)\n",
    "char2int={ch: i for i,ch in enumerate(chars_sorted)}\n",
    "char_array= np.array(chars_sorted)\n",
    "text_encoded= np.array([char2int[ch] for ch in text], dtype= np.int32)\n",
    "print('Text encoded shape: ', text_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text[:15],'== Encoding ==>',text_encoded[:15])\n",
    "print(text_encoded[15:21],'== Reverse ==>',''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ds_text_encoded= tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length= 40\n",
    "chunk_size= seq_length+1\n",
    "ds_chunks= ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "#define the function for splitting x and y\n",
    "def split_input_target(chunk):\n",
    "    input_seq= chunk[:-1]\n",
    "    target_seq= chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences= ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Input (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      "Input (x):  ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "Input (y):  'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print('Input (x): ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Input (y): ', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "BUFFER_SIZE= 10000\n",
    "ds= ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a character-level RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model= tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Setting the training parameters\n",
    "charset_size= len(char_array)\n",
    "embedding_dim= 256\n",
    "rnn_units= 512\n",
    "tf.random.set_seed(1)\n",
    "model= build_model(vocab_size=charset_size, embedding_dim= embedding_dim, rnn_units= rnn_units)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 161s 380ms/step - loss: 2.3221\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 138s 327ms/step - loss: 1.7532\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 136s 320ms/step - loss: 1.5474\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 137s 324ms/step - loss: 1.4298\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 135s 318ms/step - loss: 1.3564\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 129s 304ms/step - loss: 1.3052\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 125s 295ms/step - loss: 1.2676\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 125s 295ms/step - loss: 1.2368\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 126s 297ms/step - loss: 1.2116\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 123s 290ms/step - loss: 1.1901\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 123s 291ms/step - loss: 1.1704\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 123s 289ms/step - loss: 1.1527\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 132s 311ms/step - loss: 1.1363\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 147s 347ms/step - loss: 1.1215\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 157s 371ms/step - loss: 1.1070\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 159s 375ms/step - loss: 1.0928\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 147s 347ms/step - loss: 1.0796\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 142s 335ms/step - loss: 1.0672\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 133s 313ms/step - loss: 1.0544\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 132s 312ms/step - loss: 1.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x118122650>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits= [[1.0,1.0,1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "samples= tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.10650698 0.10650698 0.78698605]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits= [[1.0,1.0,3.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "samples= tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500,max_input_length=40, scale_factor=1.0):\n",
    "    encoded_input= [char2int[s] for s in starting_str]\n",
    "    encoded_input= tf.reshape(encoded_input, (1,-1))\n",
    "    generated_str= starting_str\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits= model(encoded_input)\n",
    "        logits= tf.squeeze(logits,0)\n",
    "        scaled_logits= logits*scale_factor\n",
    "        new_char_indx= tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        new_char_indx= tf.squeeze(new_char_indx)[-1].numpy()\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        new_char_indx= tf.expand_dims([new_char_indx],0)\n",
    "        encoded_input= tf.concat([encoded_input, new_char_indx], axis=1)\n",
    "        encoded_input= encoded_input[:,-max_input_length:]\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island is our boat was does that the unknown part of her in the chest, through the\n",
      "waters of the brig, and that doubtless, made rather in the dark\n",
      "aside.\n",
      "\n",
      "“Top? Are the car, as soon still it hastened the boat, blew to bark on board Union here, not to go do nothing could go and partly\n",
      "him, and it was impossible to add possibility, and that completular\n",
      "will\n",
      "be looked, without it do.”\n",
      "\n",
      "“No,” said Cyrus Harding.\n",
      "\n",
      "“I think that is, or store, all did rivery! And I think that clothed out of which I believe i\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model,starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:  0.10650697891920076\n",
      "Probabilities after scaling with 0.5:  0.21194155761708547\n",
      "Probabilities after scaling with 0.1:  0.31042377345300565\n"
     ]
    }
   ],
   "source": [
    "logits= np.array([1.0,1.0,3.0])\n",
    "print('Probabilities before scaling: ', tf.math.softmax(logits).numpy()[0])\n",
    "print('Probabilities after scaling with 0.5: ',tf.math.softmax(0.5*logits).numpy()[0])\n",
    "print('Probabilities after scaling with 0.1: ', tf.math.softmax(0.1*logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island or the colonists were therefore to be going to a height of the poultry-yard the convicts were of nothing could not have been a part of the basaltic water appeared to be to search for a few minutes again in the danger of the captain, while the convicts would be descended the principal rapidly of a ship in the lake, and in the single creeks, and\n",
      "the cart was suddenly in the bottom of the palisade. The destruction of the volcano, the captain examined the shore, the colonists were unable to restrai\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model,starting_str='The island', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island\n",
      "happilude New Zoas! asdesonscerstocable Island\n",
      "been ahrnocking somoth of oacthm arriked at\n",
      "similar role?.\n",
      "However, no5 caseen!\n",
      "Glamn’s capa,\n",
      "nests. evirtable pickaliar rupining; bears jomweked. Perboater, from: NI, Mrauctimb Captain Weftered,--Cpornel soon becomen; on Unlansivalcle climboding floruce\n",
      "rogan,\n",
      "for\n",
      "in ma1 Marks supped severest” prawora,\n",
      "partrwist,” requisix, happines, num\n",
      "Cranclicly I liquel duedy fromaggesh, issuped aboublifuly two acce! fould treig mingle, with\n",
      "Hondey ancapersfol\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
